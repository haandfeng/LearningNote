## conversion = target(是否购买)
0 不买
1 买

## offer= treatment(优惠政策)
0 没有优惠
-1 bogo优惠
1 discount优惠

## target_class(用户类型)
0  CN 给了优惠才买
1   CR 给不给优惠都买  (treatment =0 无优惠 and target!=0 买)
2   TN 给了优惠也不买 (treatment !=0 有优惠 and target!=0 不买)
3   SleepDog 屁也不是 (treatment !=0 有优惠 and target!=0 买)


## 算法
### 分割数据：
1. 分割训练变量和结果变量DataFrame 
	`df_model` 中分离出特征变量和目标变量。特征变量 `X` 是去除了 'target' 和 'target_class' 列之后的 DataFrame。目标变量 `y` 是 'target_class' 列。
2. 拆分训练集和测试集
   - 接着，使用 `train_test_split` 函数将数据集划分为训练集和测试集。参数 `test_size=0.3` 指定了测试集所占比例为 30%，`random_state=42` 设置了随机种子以确保可重复性，`stratify=df_model['treatment']` 根据 'treatment' 列进行分层抽样，以保证训练集和测试集中的 'treatment' 列的分布比例与原始数据集中的相同。
```python
def uplift_split(df_model:pd.DataFrame):
    ## 1 - Train-Test Split
    X = df_model.drop(['target','target_class'],axis=1)
    y = df_model.target_class
    X_train, X_test, y_train, y_test  = train_test_split(X, y,
                                       test_size=0.3,
                                       random_state=42,
                                       stratify=df_model['treatment'])
    return X_train,X_test, y_train, y_test
```

### 训练模型
XGBoost 通过在每次迭代中构建新的决策树模型来逐步提升模型性能。它通过最小化损失函数（如对数损失函数、平方损失函数等）来优化模型的预测能力。在每个迭代中，新模型的构建会尝试减小上一个模型的残差，从而使模型的预测更加准确。

这个函数的目的是使用 XGBoost 构建 uplift 模型，并生成 uplift 分数来衡量每个个体的预期提升效果。

函数中的操作包括：

1. **使用 XGBoost 模型获取 uplift 分数**：
   - 首先，创建一个新的 DataFrame `result`，其内容与测试集 `X_test` 相同。
   - 接着，使用 XGBoost 分类器 `xgb.XGBClassifier()` 对训练数据进行拟合，其中特征变量中去除了 'treatment' 列。
   - 然后，使用拟合好的模型对测试数据中除去 'treatment' 列的特征进行预测，并得到每个个体属于不同类别的概率 `uplift_proba`。
   - 将预测结果添加到 `result` DataFrame 中，并计算每个个体的 uplift 分数，公式为：
以下是 uplift score 的 LaTeX 表示：

$$
\text{uplift\_score} = \frac{\text{proba\_CN}}{\text{proba\_CN}+\text{proba\_CR}} + \frac{\text{proba\_TR}}{\text{proba\_TN}+\text{proba\_TR}} - \frac{\text{proba\_TN}}{\text{proba\_TN}+\text{proba\_TR}} - \frac{\text{proba\_CR}}{\text{proba\_CN}+\text{proba\_CR}}
$$
这个公式表示 uplift score 是四个概率值的组合，其中每个概率值代表了一个可能的情况。这个公式是 uplift modeling 中常用的一种方式，用来评估个体的预期提升效果。
- 最后，将真实的目标类别标签添加到 `result` DataFrame 中。
2. 返回包含 uplift 分数和真实目标类别的 DataFrame `result`。

这样，通过调用这个函数，你可以获取每个个体的 uplift 分数，并将其与真实的目标类别进行比较，从而进行进一步的分析或应用。

```python
def uplift_model(X_train:pd.DataFrame,
                 X_test:pd.DataFrame,
                 y_train:pd.DataFrame,
                 y_test:pd.DataFrame):
    ## 2 - Using XGB to get the uplift score
    # Create new dataframe
    result = pd.DataFrame(X_test).copy()    
    # Fit the model
    # 去除了treatment（优惠）列的拟合
    uplift_model = xgb.XGBClassifier().fit(X_train.drop('treatment', axis=1), y_train)
        # Predict using test-data
        # 预测
    uplift_proba =  uplift_model.predict_proba(X_test.drop('treatment', axis=1))
    result['proba_CN'] = uplift_proba[:,0] 
    result['proba_CR'] = uplift_proba[:,1] 
    result['proba_TN'] = uplift_proba[:,2] 
    result['proba_TR'] = uplift_proba[:,3]
    result['uplift_score'] = result.eval('\
    proba_CN/(proba_CN+proba_CR) \
    + proba_TR/(proba_TN+proba_TR) \
    - proba_TN/(proba_TN+proba_TR) \
    - proba_CR/(proba_CN+proba_CR)')  
    # Put the result 
    result['target_class'] = y_test
    return result
```